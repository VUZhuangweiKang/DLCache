{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d22241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from statistics import mean, median, stdev\n",
    "import statistics\n",
    "import time\n",
    "import warnings\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd037f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Subset\n",
    "from cifar100Dataset import *\n",
    "from DLCJob import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e3ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d526e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Cifar100 Training')\n",
    "parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet18',\n",
    "                    choices=model_names,\n",
    "                    help='model architecture: ' +\n",
    "                        ' | '.join(model_names) +\n",
    "                        ' (default: resnet18)')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('-p', '--print-freq', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                    help='use pre-trained model')\n",
    "parser.add_argument('--world-size', default=-1, type=int,\n",
    "                    help='number of nodes for distributed training')\n",
    "parser.add_argument('--rank', default=-1, type=int,\n",
    "                    help='node rank for distributed training')\n",
    "parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,\n",
    "                    help='url used to set up distributed training')\n",
    "parser.add_argument('--dist-backend', default='nccl', type=str,\n",
    "                    help='distributed backend')\n",
    "parser.add_argument('--seed', default=1, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument('--gpu', default=0, type=int,\n",
    "                    help='GPU id to use.')\n",
    "parser.add_argument('--multiprocessing-distributed', action='store_true',\n",
    "                    help='Use multi-processing distributed training to launch '\n",
    "                         'N processes per node, which has N GPUs. This is the '\n",
    "                         'fastest way to use PyTorch for either single node or '\n",
    "                         'multi node data parallel training')\n",
    "\n",
    "best_acc1 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeffc059",
   "metadata": {},
   "outputs": [],
   "source": [
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d258c046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szhou56/anaconda3/envs/DLC/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.\n",
      "  \"\"\"\n",
      "/home/szhou56/anaconda3/envs/DLC/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    cudnn.deterministic = True\n",
    "    warnings.warn('You have chosen to seed training. '\n",
    "                  'This will turn on the CUDNN deterministic setting, '\n",
    "                  'which can slow down your training considerably! '\n",
    "                  'You may see unexpected behavior when restarting '\n",
    "                  'from checkpoints.')\n",
    "\n",
    "if args.gpu is not None:\n",
    "    warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                  'disable data parallelism.')\n",
    "\n",
    "if args.dist_url == \"env://\" and args.world_size == -1:\n",
    "    args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "\n",
    "ngpus_per_node = torch.cuda.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecdfa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply call main_worker function\n",
    "exp_summary = []\n",
    "exp_start = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f78723f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: 0 for training\n"
     ]
    }
   ],
   "source": [
    "global best_acc1\n",
    "args.gpu = args.gpu\n",
    "\n",
    "if args.gpu is not None:\n",
    "    print(\"Use GPU: {} for training\".format(args.gpu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605f9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.distributed:\n",
    "    if args.dist_url == \"env://\" and args.rank == -1:\n",
    "        args.rank = int(os.environ[\"RANK\"])\n",
    "    if args.multiprocessing_distributed:\n",
    "        # For multiprocessing distributed training, rank needs to be the\n",
    "        # global rank among all the processes\n",
    "        args.rank = args.rank * ngpus_per_node + gpu\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "                            world_size=args.world_size, rank=args.rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e075f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet18'\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "if args.pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "    model = models.__dict__[args.arch](pretrained=True)\n",
    "else:\n",
    "    print(\"=> creating model '{}'\".format(args.arch))\n",
    "    model = models.__dict__[args.arch]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5df9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('using CPU, this will be slow')\n",
    "elif args.distributed:\n",
    "    # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "    # should always set the single device scope, otherwise,\n",
    "    # DistributedDataParallel will use all available devices.\n",
    "    if args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model.cuda(args.gpu)\n",
    "        # When using a single GPU per process and per\n",
    "        # DistributedDataParallel, we need to divide the batch size\n",
    "        # ourselves based on the total number of GPUs of the current node.\n",
    "        args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "        args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "    else:\n",
    "        model.cuda()\n",
    "        # DistributedDataParallel will divide and allocate batch_size to all\n",
    "        # available GPUs if device_ids are not set\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "elif args.gpu is not None:\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    model = model.cuda(args.gpu)\n",
    "else:\n",
    "    # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "    if args.arch.startswith('alexnet') or args.arch.startswith('vgg'):\n",
    "        model.features = torch.nn.DataParallel(model.features)\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9784a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function (criterion), optimizer, and learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27097206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        if args.gpu is None:\n",
    "            checkpoint = torch.load(args.resume)\n",
    "        else:\n",
    "            # Map model to be loaded to specified single gpu.\n",
    "            loc = 'cuda:{}'.format(args.gpu)\n",
    "            checkpoint = torch.load(args.resume, map_location=loc)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_acc1']\n",
    "        if args.gpu is not None:\n",
    "            # best_acc1 may be from a checkpoint from a different GPU\n",
    "            best_acc1 = best_acc1.to(args.gpu)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c722e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Data loading code\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3576b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/szhou56/Documents/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a80d9a83",
   "metadata": {},
   "outputs": [],
   "source": [
    " transform_train = transforms.Compose([\n",
    "    # transforms.ToPILImage(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "# data prep for test set\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22797f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [\n",
    "    [\"train\", \"16019d7e3df5f24257cddd939b257f8d\"],\n",
    "]\n",
    "\n",
    "test_list = [\n",
    "    [\"test\", \"f0ef6b0ae62326f3e7ffdfab6717acfc\"],\n",
    "]\n",
    "downloaded_list = train_list\n",
    "folder = '/home/szhou56/Documents/data/cifar-100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737e0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "targets =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "167fbcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "for file_name, checksum in downloaded_list:\n",
    "    file_path = os.path.join(folder,file_name)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        entry = pickle.load(f, encoding=\"latin1\")\n",
    "        data.append(entry[\"data\"])\n",
    "        print(len(entry[\"data\"]))\n",
    "        if \"labels\" in entry:\n",
    "            targets.extend(entry[\"labels\"])\n",
    "            print(entry[\"labels\"])\n",
    "        else:\n",
    "            targets.extend(entry[\"fine_labels\"])\n",
    "            print(len(entry[\"fine_labels\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "369d865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 253 253 ... 253 253 255]\n"
     ]
    }
   ],
   "source": [
    "print(entry[\"data\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2dab6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,101):\n",
    "    folder1 = '/home/szhou56/Documents/data/cifar-100/train1'\n",
    "    \n",
    "    file_class = str(i)\n",
    "    \n",
    "    file_path = os.path.join(folder1,file_class)\n",
    "    os.mkdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "629a766b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ...  10  59  79]\n",
      " [255 253 253 ... 253 253 255]\n",
      " [250 248 247 ... 194 207 228]\n",
      " ...\n",
      " [248 240 236 ... 180 174 205]\n",
      " [156 151 151 ... 114 107 126]\n",
      " [ 31  30  31 ...  72  69  67]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(entry[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff64da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "for i in range(len(entry[\"data\"])):\n",
    "    \n",
    "    file_class = entry[\"fine_labels\"][i]\n",
    "    folder1 = '/home/szhou56/Documents/data/cifar-100/train1'\n",
    "    file_class = str(file_class)\n",
    "    file_name = str(uuid.uuid1())\n",
    "    file = file_name+ '.npy'\n",
    "    file_path = os.path.join(folder1,file_class,file)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        np.save(f, np.array(entry[\"data\"][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae38417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 100):\n",
    "    folder1 = '/home/szhou56/Documents/data/cifar-100/train1'\n",
    "    file_class = str(i)\n",
    "    file = 'file.txt'\n",
    "    file_path = os.path.join(folder1,file_class,file)\n",
    "    with open(file_path,\"a+\") as f:\n",
    "        f.write(str(traindata[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9cedb081",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(entry[\"data\"])):\n",
    "    file_class = str(entry[\"fine_labels\"][i])\n",
    "    file = 'file.txt'\n",
    "    file_path = os.path.join(folder1,file_class,file)\n",
    "    with open(file_path,\"a+\") as f:\n",
    "        f.write(str(entry[\"data\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4b11c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack(data).reshape(-1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54471c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.transpose((0, 2, 3, 1))  # convert to HWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0050c120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [195, 205, 193],\n",
       "         [212, 224, 204],\n",
       "         [182, 194, 167]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [170, 176, 150],\n",
       "         [161, 168, 130],\n",
       "         [146, 154, 113]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [189, 199, 169],\n",
       "         [166, 178, 130],\n",
       "         [121, 133,  87]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[148, 185,  79],\n",
       "         [142, 182,  57],\n",
       "         [140, 179,  60],\n",
       "         ...,\n",
       "         [ 30,  17,   1],\n",
       "         [ 65,  62,  15],\n",
       "         [ 76,  77,  20]],\n",
       "\n",
       "        [[122, 157,  66],\n",
       "         [120, 155,  58],\n",
       "         [126, 160,  71],\n",
       "         ...,\n",
       "         [ 22,  16,   3],\n",
       "         [ 97, 112,  56],\n",
       "         [141, 161,  87]],\n",
       "\n",
       "        [[ 87, 122,  41],\n",
       "         [ 88, 122,  39],\n",
       "         [101, 134,  56],\n",
       "         ...,\n",
       "         [ 34,  36,  10],\n",
       "         [105, 133,  59],\n",
       "         [138, 173,  79]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [255, 255, 255]]],\n",
       "\n",
       "\n",
       "       [[[250, 250, 248],\n",
       "         [248, 249, 243],\n",
       "         [247, 248, 239],\n",
       "         ...,\n",
       "         [250, 250, 246],\n",
       "         [250, 250, 246],\n",
       "         [249, 250, 246]],\n",
       "\n",
       "        [[250, 251, 245],\n",
       "         [248, 249, 238],\n",
       "         [247, 247, 234],\n",
       "         ...,\n",
       "         [251, 251, 242],\n",
       "         [251, 252, 243],\n",
       "         [250, 251, 243]],\n",
       "\n",
       "        [[251, 251, 244],\n",
       "         [250, 248, 237],\n",
       "         [250, 245, 233],\n",
       "         ...,\n",
       "         [250, 249, 238],\n",
       "         [250, 249, 240],\n",
       "         [250, 249, 242]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[221, 213, 191],\n",
       "         [221, 206, 176],\n",
       "         [225, 207, 181],\n",
       "         ...,\n",
       "         [199, 176, 134],\n",
       "         [207, 193, 165],\n",
       "         [233, 229, 226]],\n",
       "\n",
       "        [[225, 223, 204],\n",
       "         [227, 219, 196],\n",
       "         [229, 216, 200],\n",
       "         ...,\n",
       "         [204, 185, 151],\n",
       "         [212, 201, 180],\n",
       "         [234, 232, 228]],\n",
       "\n",
       "        [[233, 233, 226],\n",
       "         [234, 232, 224],\n",
       "         [235, 230, 225],\n",
       "         ...,\n",
       "         [219, 209, 194],\n",
       "         [223, 216, 207],\n",
       "         [232, 230, 228]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[248, 244, 242],\n",
       "         [240, 232, 223],\n",
       "         [236, 232, 223],\n",
       "         ...,\n",
       "         [233, 229, 222],\n",
       "         [230, 228, 222],\n",
       "         [238, 237, 233]],\n",
       "\n",
       "        [[225, 213, 204],\n",
       "         [186, 167, 149],\n",
       "         [175, 159, 140],\n",
       "         ...,\n",
       "         [163, 148, 134],\n",
       "         [156, 144, 133],\n",
       "         [192, 184, 176]],\n",
       "\n",
       "        [[209, 194, 179],\n",
       "         [144, 120,  95],\n",
       "         [139, 115,  87],\n",
       "         ...,\n",
       "         [109,  86,  67],\n",
       "         [109,  90,  76],\n",
       "         [157, 145, 135]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[161, 159, 153],\n",
       "         [ 39,  34,  28],\n",
       "         [ 28,  20,  14],\n",
       "         ...,\n",
       "         [ 93,  72,  53],\n",
       "         [ 85,  67,  50],\n",
       "         [136, 126, 115]],\n",
       "\n",
       "        [[181, 179, 172],\n",
       "         [ 86,  83,  77],\n",
       "         [ 71,  68,  62],\n",
       "         ...,\n",
       "         [122, 103,  89],\n",
       "         [105,  92,  82],\n",
       "         [151, 145, 141]],\n",
       "\n",
       "        [[224, 223, 218],\n",
       "         [180, 180, 175],\n",
       "         [173, 172, 167],\n",
       "         ...,\n",
       "         [196, 187, 180],\n",
       "         [183, 178, 174],\n",
       "         [204, 205, 205]]],\n",
       "\n",
       "\n",
       "       [[[156, 154, 137],\n",
       "         [151, 146, 123],\n",
       "         [151, 144, 125],\n",
       "         ...,\n",
       "         [155, 150, 129],\n",
       "         [152, 148, 125],\n",
       "         [186, 184, 163]],\n",
       "\n",
       "        [[110, 106,  77],\n",
       "         [116, 108,  62],\n",
       "         [114, 101,  57],\n",
       "         ...,\n",
       "         [116, 106,  61],\n",
       "         [111, 103,  56],\n",
       "         [134, 129,  92]],\n",
       "\n",
       "        [[116, 112,  82],\n",
       "         [124, 118,  66],\n",
       "         [128, 118,  67],\n",
       "         ...,\n",
       "         [ 99,  84,  43],\n",
       "         [101,  87,  43],\n",
       "         [129, 118,  86]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[109, 101,  74],\n",
       "         [112, 100,  54],\n",
       "         [118, 105,  62],\n",
       "         ...,\n",
       "         [126, 113,  65],\n",
       "         [126, 111,  61],\n",
       "         [138, 124,  89]],\n",
       "\n",
       "        [[ 98,  92,  63],\n",
       "         [ 93,  82,  35],\n",
       "         [ 96,  83,  38],\n",
       "         ...,\n",
       "         [112,  96,  47],\n",
       "         [109,  92,  45],\n",
       "         [127, 113,  80]],\n",
       "\n",
       "        [[170, 167, 145],\n",
       "         [160, 153, 118],\n",
       "         [163, 152, 119],\n",
       "         ...,\n",
       "         [161, 151, 114],\n",
       "         [156, 144, 107],\n",
       "         [163, 154, 126]]],\n",
       "\n",
       "\n",
       "       [[[ 31,  67, 122],\n",
       "         [ 30,  68, 124],\n",
       "         [ 31,  69, 126],\n",
       "         ...,\n",
       "         [ 32,  70, 129],\n",
       "         [ 32,  70, 125],\n",
       "         [ 32,  69, 122]],\n",
       "\n",
       "        [[ 29,  68, 126],\n",
       "         [ 28,  69, 128],\n",
       "         [ 30,  69, 130],\n",
       "         ...,\n",
       "         [ 32,  70, 131],\n",
       "         [ 32,  69, 127],\n",
       "         [ 31,  69, 124]],\n",
       "\n",
       "        [[ 30,  67, 126],\n",
       "         [ 29,  68, 128],\n",
       "         [ 30,  69, 130],\n",
       "         ...,\n",
       "         [ 32,  72, 132],\n",
       "         [ 31,  70, 130],\n",
       "         [ 30,  69, 127]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 39,  41,  76],\n",
       "         [ 38,  42,  76],\n",
       "         [ 38,  44,  78],\n",
       "         ...,\n",
       "         [ 39,  44,  79],\n",
       "         [ 38,  42,  77],\n",
       "         [ 39,  41,  76]],\n",
       "\n",
       "        [[ 40,  39,  73],\n",
       "         [ 39,  40,  74],\n",
       "         [ 39,  41,  76],\n",
       "         ...,\n",
       "         [ 39,  41,  76],\n",
       "         [ 40,  41,  74],\n",
       "         [ 40,  39,  73]],\n",
       "\n",
       "        [[ 40,  39,  70],\n",
       "         [ 40,  39,  71],\n",
       "         [ 40,  39,  72],\n",
       "         ...,\n",
       "         [ 41,  38,  72],\n",
       "         [ 39,  38,  69],\n",
       "         [ 40,  37,  67]]]], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62c231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
