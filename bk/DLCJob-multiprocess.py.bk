import os
import json
import bson
import math
import functools
import statistics
import random
import time
from datetime import datetime
import grpc
import grpctool.dbus_pb2 as pb
import grpctool.dbus_pb2_grpc as pb_grpc
import threading
import queue
from typing import (
    Callable,
    Dict,
    Generic,
    Iterable,
    Iterator,
    List,
    Union,
    Optional,
    Sequence,
    Tuple,
    TypeVar,
)
import torch
import torch.multiprocessing as multiprocessing
from torch.utils.data import Dataset, DataLoader, Sampler, BatchSampler, RandomSampler, SequentialSampler, _DatasetKind
from torch.utils.data.dataloader import _get_distributed_settings, _BaseDataLoaderIter
from torch.utils.data.datapipes.datapipe import (
    _MapDataPipeSerializationWrapper, 
    IterDataPipe, 
    _IterDataPipeSerializationWrapper, 
    IterableDataset, 
    MapDataPipe,
)
from torch.utils.data import _utils
from torch.utils.data.dataloader import _worker_init_fn_t, _collate_fn_t, default_collate
import worker
from utils import *

COOL_DOWN_SEC = 600
class CHUNK_STATUS:
    PREPARE = 0
    ACTIVE = 1
    PENDING = 2
    COOL_DOWN = 3
    INACTIVE = 4

T_co = TypeVar('T_co', covariant=True)


class DLCJobDataset(Dataset[T_co]):
    def __init__(self, dtype='train'):
        """An abstract class subclassing the torch.utils.data.Dataset class
        
        All datasets that represent a map from keys to data samples should subclass
        it. All subclasses should overwrite :meth:`process`, supporting pre-processing loaded data. 
        Subclasses should also overwrite meth:`__getitem__`, supporting fetching a
        data sample for a given key. Subclasses could also optionally overwrite
        :meth:`__len__`, which is expected to return the size of the dataset by many
        :class:`~torch.utils.data.Sampler` implementations and the default options
        of :class:`~DLCJobDataLoader`.
        
        .. note::
        Subclassing ~DLCJobDataset will load data under provided keys from DLCache to var:`self._samples` as Map<Key, Value>.
        Overwriting meth:`process` allows you to replace var:`self._samples` and var:`self._targets` with
        iteratable variables that can be iterated in meth:`__get_item__`.
        
        Args:
            dtype: dataset type, train/validation/test for supervised and unsupervised training/testing
        """
        if dtype not in ["train", "validation", "test"]:
            raise ValueError("invalid dataset type".format(dtype))
        
        self.dtype = dtype
        jobinfo = "/share/{}.json".format(os.environ.get('JOBNAME'))
        while not os.path.exists(jobinfo): pass
        with open(jobinfo, 'rb') as f:
            job_meta = json.load(f)

        self.bucket = job_meta['datasource']['bucket']
        self.qos = job_meta["qos"]
        self.lazy = job_meta['qos']['LazyLoading']
        self.usecache = job_meta['qos']['UseCache']
        
        self._sample_chunks = []
        self._target_chunks = []
        
        self._samples = {}
        self._targets = {}
        if self.usecache:
            # from pymongo.mongo_client import MongoClient
            import pandas as pd
            # mongo_client = MongoClient(job_meta['mongoUri'])
            # self.db = mongo_client.Cacher
            # cursor = self.db.Job.find_one({"Meta.JobId": job_meta['jobId']})
            # self.job_info = {"ChunkETags": cursor["ChunkETags"], "Meta": cursor["Meta"]}
            # manifest_etags = self.job_info["ChunkETags"][self.dtype]["manifests"]
            # self.manifest = None
            # for manifest_etag in manifest_etags:
            #     manifest_chunk = self.db.Datasets.find_one({"ETag": manifest_etag})
            #     manifest_fpath = "/{}/{}".format(manifest_chunk['Location'], manifest_etag)
            #     if self.manifest is None:
            #         self.manifest = pd.read_csv(manifest_fpath)
            #     else:
            #         self.manifest = pd.concat([self.manifest, pd.read_csv(manifest_fpath)])
            # self._load_chunks()
            
            # with open('job_info.json', 'w') as f:
            #     json.dump(self.job_info, f)
            # self.manifest.to_csv('{}_manifest.csv'.format(self.dtype), index=False)
            
            with open('job_info.json', 'r') as f:
                self.job_info = json.load(f)
            self.chunk_etags = self.job_info["ChunkETags"]
            self.manifest = pd.read_csv('{}_manifest.csv'.format(self.dtype))
        else:
            import boto3
            cloudSecret = {
                "aws_access_key_id": read_secret('aws_access_key_id'),
                "aws_secret_access_key": read_secret('aws_secret_access_key'),
                "region_name": read_secret('region_name')
            }
            s3_session = boto3.Session(**cloudSecret)
            self.s3_client = s3_session.client('s3')
            self._load_chunks_from_cloud()
            
        self.load_data(partition_index=0)
        # self._miss_queue = multiprocessing.Queue()
        # self._handle_miss_thread = multiprocessing.Process(target=self._handle_miss, daemon=True)
        # self._handle_miss_thread.start()

    def __default_get_item__(self, index):            
        if self.lazy:         
            if self.usecache:
                sample, target = self._samples[index], self._targets[index]
                try:
                    X = self.__sample_reader__(sample)
                    Y = self.__target_reader__(target)
                except FileNotFoundError:
                    print('miss nfs file {}'.format(sample))
                    etag = sample.split('/')[-1]
                    self._miss_queue.put(etag)
                    sub_idx = random.randint(0, len(self) - 1)
                    X, Y = self.__default_get_item__(sub_idx)
            else:
                X = self.s3_client.get_object(Bucket=self.bucket, Key=self._samples[index])['Body'].read()
                Y = None
                if len(self._targets) > 0:
                    Y = self._targets[index]
                    if 'Contents' in self.s3_client.list_objects(Bucket=self.bucket, Prefix=str(Y)):
                        Y = self.s3_client.get_object(Bucket=self.bucket, Key=Y)['Body'].read()            
            return (X, Y) if Y is not None else X
        else:
            return (self._samples[index], self._targets[index])

    def _handle_miss(self):
        # grpc consumes high memory
        manager_uri = "dlcpod-manager:50051"
        while True:
            miss_etag = self._miss_queue.get(block=True)
            with grpc.insecure_channel(manager_uri) as channel:
                cred = pb.Credential(username=read_secret('dlcache_user'), password=read_secret('dlcache_pwd'))
                stub = pb_grpc.DataMissStub(channel)
                stub.call(pb.DataMissRequest(cred=cred, etag=miss_etag))
            del cred, stub, miss_etag
            
    # TODO: mongo find is very time-consuming for large small file-based image dataset
    def _load_chunks(self):
        """Load all chunks (MongoDB query result) of the given dataset. 
        
        In the LazyLoading mode, there is only 1 group because no memory pressure.
        Otherwise, we group chunks to make them fit the MaxPartMill constraint.

        Returns:
            None: initialize the self._sample_chunks and self._target_chunks
        """
        import numpy as np
        def load(etags):
            chunks = []
            if etags:
                chunks_iter = self.db.Datasets.find({"ETag": {"$in": etags}})
                for chunk in chunks_iter:
                    sel_keys = ['Key', 'Location', 'ChunkETag']
                    chunks.append([chunk[k] for k in sel_keys])
                del chunks_iter
            return np.array(chunks)

        chunk_etags = self.job_info['ChunkETags'][self.dtype]
        self._sample_chunks = load(chunk_etags['samples'])
        if self.lazy:
            self._sample_chunks = np.expand_dims(self._sample_chunks, axis=0)
        self._target_chunks = load(chunk_etags['targets'])
        
    # dataset shouldn't be compressed when using this function
    def _load_chunks_from_cloud(self):
        paginator = self.s3_client.get_paginator('list_objects_v2')       
        def load_pages(keys):
            if keys:
                pages = []
                for k in keys:
                    pages.extend(paginator.paginate(Bucket=self.bucket, Prefix=k))
                return pages
            return None

        keys = self.job_info["Meta"]['Datasource']['keys'][self.dtype]
        
        def load(keys):
            chunks = []
            if keys:
                pages = load_pages(keys)
                for i in range(len(pages)):
                    tmp = []
                    for j in range(len(pages[i]['Contents'])):
                        dataobj = pages[i]["Contents"][j]
                        tmp.append(dataobj)
                    chunks.append(tmp)
            return chunks
        
        self._sample_chunks = load(keys['samples'])
        self._target_chunks = load(keys['targets'])
        
    def load_data(self, partition_index=0):
        """Load file paths or actual data in the given partition
        
        Initialize the self._samples and self._targets, where self._samples is a dict with format {key: file_path/data}
        user performs data (X and y) processing in the process function, that convert self._samples ans self._targets
        from dict to iteratable X, y
        
        If a chunk is a compressed, we generate a dummy key for individual files.
        We start operating on individual data items from this function. Before this, all operations are on chunks.
        
        Samples are matched with corresponding targets based on the manifest file provided by user, which specifies the 
        mappings between X and y.
        
        Only file-based datasets might have the manifest file.
        
        Args:
            partition_index (int): file-based (LazyLoading) dataset only has one partition, so the partition_index = 0
                             tabular dataset might split file to multiple partitions
        """
        
        def load(chunks, reader):
            data = {}
            for chunk in chunks[partition_index]:
                key, loc, chunk_etag = chunk
                if self.usecache:
                    chunk_path = '/{}/{}'.format(loc, chunk_etag)
                    # decompressed folder, so key has the .tar.gz extension
                    if os.path.isdir(chunk_path):
                        # We assume data won't be immediately deleted after being downloaded by Manager.
                        for root, dirs, files in os.walk(chunk_path):
                            for name in files:
                                p = os.path.join(root, name)
                                dummy_key = key + p.replace(chunk_path, '')
                                data[dummy_key] = p if self.lazy else reader(p)
                    else:
                        data[key] = chunk_path if self.lazy else reader(chunk_path)
                else:
                    data[key] = key
            return data
        
        '''self._samples and self._targets are dictionaries with format {'cloud_key': 'nfs_path'}
        '''
        if os.path.exists('{}_samples.json'.format(self.dtype)):
            with open('{}_samples.json'.format(self.dtype), 'r') as f:
                self._samples = json.load(f)
        else:
            self._samples = load(self._sample_chunks, self.__sample_reader__)
            with open('{}_samples.json'.format(self.dtype), 'w') as f:
                json.dump(self._samples, f)
        if self._target_chunks:
            self._targets = load(self._target_chunks, self.__target_reader__)
        
        # self._samples, self._targets = self.__process__()
        self.__process__()
        
    def __sample_reader__(self, item):
        # raise NotImplementedError
        pass
    
    def __target_reader__(self, item):
        # raise NotImplementedError
        pass
    
    def __process__(self):
        """process self._samples ans self.target

        Return iteratable X, y that can be indexed by __get_item__
        
        Raises:
            NotImplementedError: _description_
        """
        raise NotImplementedError
    
    def __getitem__(self, index: int):
        """get the sample and target at the given index
        Args:
            index (int): Index

        Returns:
            (Any): Sample and meta data, optionally transformed by the respective transforms.
        """
        return self.__default_get_item__(index)
    
    def __len__(self) -> int:
        return len(self._samples)
        

        
class _DLCJobDataLoaderIter(_BaseDataLoaderIter):
    def __init__(self, dataset: DLCJobDataset, 
                 batch_size: Optional[int] = 1, shuffle: bool = False, sampler: Union[Sampler, Iterable, None] = None,
                 batch_sampler: Union[Sampler[Sequence], Iterable[Sequence], None] = None,
                 num_workers: int = 0, collate_fn: Optional[_collate_fn_t] = None,
                 pin_memory: bool = False, drop_last: bool = False,
                 timeout: float = 0, worker_init_fn: Optional[_worker_init_fn_t] = None,
                 multiprocessing_context=None, generator=None, *, prefetch_factor: int = 2,
                 persistent_workers: bool = False, pin_memory_device: str = "", tune_num_workers_frequency: int = 20, max_num_workers: int = None):
        r"""
        Data loader. Combines a dataset and a sampler, and provides an iterable over
        the given dataset.

        The :class:`~torch.utils.data.DataLoader` supports both map-style and
        iterable-style datasets with single- or multi-process loading, customizing
        loading order and optional automatic batching (collation) and memory pinning.

        See :py:mod:`torch.utils.data` documentation page for more details.

        Args:
            dataset (Dataset): dataset from which to load the data.
            batch_size (int, optional): how many samples per batch to load
                (default: ``1``).
            shuffle (bool, optional): set to ``True`` to have the data reshuffled
                at every epoch (default: ``False``).
            sampler (Sampler or Iterable, optional): defines the strategy to draw
                samples from the dataset. Can be any ``Iterable`` with ``__len__``
                implemented. If specified, :attr:`shuffle` must not be specified.
            batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but
                returns a batch of indices at a time. Mutually exclusive with
                :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,
                and :attr:`drop_last`.
            num_workers (int, optional): how many subprocesses to use for data
                loading. ``0`` means that the data will be loaded in the main process.
                (default: ``0``)
            collate_fn (callable, optional): merges a list of samples to form a
                mini-batch of Tensor(s).  Used when using batched loading from a
                map-style dataset.
            pin_memory (bool, optional): If ``True``, the data loader will copy Tensors
                into CUDA pinned memory before returning them.  If your data elements
                are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,
                see the example below.
            drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,
                if the dataset size is not divisible by the batch size. If ``False`` and
                the size of dataset is not divisible by the batch size, then the last batch
                will be smaller. (default: ``False``)
            timeout (numeric, optional): if positive, the timeout value for collecting a batch
                from workers. Should always be non-negative. (default: ``0``)
            worker_init_fn (callable, optional): If not ``None``, this will be called on each
                worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as
                input, after seeding and before data loading. (default: ``None``)
            generator (torch.Generator, optional): If not ``None``, this RNG will be used
                by RandomSampler to generate random indexes and multiprocessing to generate
                `base_seed` for workers. (default: ``None``)
            prefetch_factor (int, optional, keyword-only arg): Number of samples loaded
                in advance by each worker. ``2`` means there will be a total of
                2 * num_workers samples prefetched across all workers. (default: ``2``)
            persistent_workers (bool, optional): If ``True``, the data loader will not shutdown
                the worker processes after a dataset has been consumed once. This allows to
                maintain the workers `Dataset` instances alive. (default: ``False``)
            pin_memory_device (str, optional): the data loader will copy Tensors
                into device pinned memory before returning them if pin_memory is set to true.


        .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`
                    cannot be an unpicklable object, e.g., a lambda function. See
                    :ref:`multiprocessing-best-practices` on more details related
                    to multiprocessing in PyTorch.

        .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.
                    When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,
                    it instead returns an estimate based on ``len(dataset) / batch_size``, with proper
                    rounding depending on :attr:`drop_last`, regardless of multi-process loading
                    configurations. This represents the best guess PyTorch can make because PyTorch
                    trusts user :attr:`dataset` code in correctly handling multi-process
                    loading to avoid duplicate data.

                    However, if sharding results in from threading import Thread

        .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and
                    :ref:`data-loading-randomness` notes for random seed related questions.
        """
        super(_DLCJobDataLoaderIter, self).__init__(loader)
        if num_workers < 0:
            raise ValueError('num_workers option should be non-negative; '
                             'use num_workers=0 to disable multiprocessing.')

        if timeout < 0:
            raise ValueError('timeout option should be non-negative')

        if num_workers == 0 and prefetch_factor is not None:
            raise ValueError('prefetch_factor option could only be specified in multiprocessing.'
                             'let num_workers > 0 to enable multiprocessing, otherwise set prefetch_factor to None.')
        elif num_workers > 0 and prefetch_factor is None:
            prefetch_factor = 2
        elif prefetch_factor is not None and prefetch_factor < 0:
            raise ValueError('prefetch_factor option should be non-negative')

        if persistent_workers and num_workers == 0:
            raise ValueError('persistent_workers option needs num_workers > 0')
        
        self.dataset = dataset
        self.lazy = dataset.qos['LazyLoading']
        self._shared_seed = None
        
        self.batch_size = batch_size
        self.shuffle = bool(shuffle)
        self.sampler = sampler
        self.batch_sampler = batch_sampler
        self.num_workers = num_workers
        self.pin_memory = pin_memory
        self.drop_last = drop_last
        self.timeout = timeout
        
        if multiprocessing_context is None:
            self.multiprocessing_context = multiprocessing
        else:
            self.multiprocessing_context = multiprocessing_context
            
        # Adds forward compatibilities so classic DataLoader can work with DataPipes:
        #   _DataPipeSerializationWrapper container makes it easier to serialize without redefining pickler
        if isinstance(self.dataset, IterDataPipe):
            self.dataset = _IterDataPipeSerializationWrapper(self.dataset)
        elif isinstance(self.dataset, MapDataPipe):
            self.dataset = _MapDataPipeSerializationWrapper(self.dataset)

        # Arg-check dataset related before checking samplers because we want to
        # tell users that iterable-style datasets are incompatible with custom
        # samplers first, so that they don't learn that this combo doesn't work
        # after spending time fixing the custom sampler errors.
        if isinstance(dataset, IterableDataset):
            self._dataset_kind = _DatasetKind.Iterable
            # NOTE [ Custom Samplers and IterableDataset ]
            #
            # `IterableDataset` does not support custom `batch_sampler` or
            # `sampler` since the key is irrelevant (unless we support
            # generator-style dataset one day...).
            #
            # For `sampler`, we always create a dummy sampler. This is an
            # infinite sampler even when the dataset may have an implemented
            # finite `__len__` because in multi-process data loading, naive
            # settings will return duplicated data (which may be desired), and
            # thus using a sampler with length matching that of dataset will
            # cause data lost (you may have duplicates of the first couple
            # batches, but never see anything afterwards). Therefore,
            # `Iterabledataset` always uses an infinite sampler, an instance of
            # `_InfiniteConstantSampler` defined above.
            #
            # A custom `batch_sampler` essentially only controls the batch size.
            # However, it is unclear how useful it would be since an iterable-style
            # dataset can handle that within itself. Moreover, it is pointless
            # in multi-process data loading as the assignment order of batches
            # to workers is an implementation detail so users can not control
            # how to batchify each worker's iterable. Thus, we disable this
            # option. If this turns out to be useful in future, we can re-enable
            # this, and support custom samplers that specify the assignments to
            # specific workers.
            if isinstance(dataset, IterDataPipe):
                if shuffle is not None:
                    dataset = torch.utils.data.graph_settings.apply_shuffle_settings(dataset, shuffle=shuffle)
            # We cannot check `shuffle is not None` here, since previously `shuffle=False` was the default.
            elif shuffle not in {False, None}:
                raise ValueError(
                    "DataLoader with IterableDataset: expected unspecified "
                    "shuffle option, but got shuffle={}".format(shuffle))

            if sampler is not None:
                # See NOTE [ Custom Samplers and IterableDataset ]
                raise ValueError(
                    "DataLoader with IterableDataset: expected unspecified "
                    "sampler option, but got sampler={}".format(sampler))
            elif batch_sampler is not None:
                # See NOTE [ Custom Samplers and IterableDataset ]
                raise ValueError(
                    "DataLoader with IterableDataset: expected unspecified "
                    "batch_sampler option, but got batch_sampler={}".format(batch_sampler))
        else:
            shuffle = bool(shuffle)
            self._dataset_kind = _DatasetKind.Map
        
        if max_num_workers is None:
            self.max_num_workers = self.multiprocessing_context.cpu_count() // 2
        else:
            self.max_num_workers = max_num_workers
        
        if sampler is not None and shuffle:
            raise ValueError('sampler option is mutually exclusive with '
                             'shuffle')

        if batch_sampler is not None:
            # auto_collation with custom batch_sampler
            if batch_size != 1 or shuffle or sampler is not None or drop_last:
                raise ValueError('batch_sampler option is mutually exclusive '
                                 'with batch_size, shuffle, sampler, and '
                                 'drop_last')
            batch_size = None
            drop_last = False
        elif batch_size is None:
            # no auto_collation
            if drop_last:
                raise ValueError('batch_size=None option disables auto-batching '
                                 'and is mutually exclusive with drop_last')
                
        self._init_index_sampler()
        
        if collate_fn is None:
            if self.auto_collation:
                collate_fn = _utils.collate.default_collate
            else:
                collate_fn = _utils.collate.default_convert
        self.collate_fn = collate_fn        
        
        self.generator = generator
        self.prefetch_factor = prefetch_factor
        self.persistent_workers = persistent_workers
        self.tune_num_workers_frequency = tune_num_workers_frequency  
                
        self.num_batches = len(self)
        self._partition_idx = 0
        self.worker_init_fn = worker_init_fn
        ws, rank = _get_distributed_settings()
        self._world_size = ws
        self._rank = rank
        self.worker_init_fn = functools.partial(worker._sharding_worker_init_fn, self.worker_init_fn, self._world_size, self._rank)
        
        self._base_seed = torch.empty((), dtype=torch.int64).random_(generator=self.generator).item()
        self._index_queues = []
        self._workers = []
        self._shutdown = False
        self._worker_result_queue = self.multiprocessing_context.Queue()    
        self._workers_down_event = self.multiprocessing_context.Event()
        self._worker_queue_idx_cycle = worker.WorkerQueueIndexCycle()
        self._worker_pids_set = False
        self._shutdown = False
        self._active_workers = 0
        for i in range(self.num_workers):
            self._spawn_worker(i)
            
        self.pin_memory = self.pin_memory and torch.cuda.is_available()
        self.pin_memory_device = pin_memory_device
        if (len(self.pin_memory_device) == 0):
            self.pin_memory = self.pin_memory and torch.cuda.is_available()
            self.pin_memory_device = None
        else:
            if not self.pin_memory:
                warn_msg = ("pin memory device is set and pin_memory flag is not used then device pinned memory won't be used"
                            "please set pin_memory to true, if you need to use the device pin memory")
                warnings.warn(warn_msg)
                
        if self.pin_memory:
            self._pin_memory_thread_done_event = threading.Event()

            # Queue is not type-annotated
            self._data_queue = queue.Queue()  # type: ignore[var-annotated]
            if self.pin_memory_device == "xpu":
                current_device = torch.xpu.current_device()  # type: ignore[attr-defined]
            else:
                current_device = torch.cuda.current_device()  # choose cuda for default
            pin_memory_thread = threading.Thread(
                target=_utils.pin_memory._pin_memory_loop,
                args=(self._worker_result_queue, self._data_queue,
                      current_device,
                      self._pin_memory_thread_done_event, self.pin_memory_device))
            pin_memory_thread.daemon = True
            pin_memory_thread.start()
            # Similar to workers (see comment above), we only register
            # pin_memory_thread once it is started.
            self._pin_memory_thread = pin_memory_thread
        else:
            self._data_queue = self._worker_result_queue
        
        self._cool_down_proc = None
        # self._mongo_operation_queue = queue.Queue()
        # threading.Thread(target=self.async_mongo_operator, daemon=True).start()
        
        # In some rare cases, persistent workers (daemonic processes)
        # would be terminated before `__del__` of iterator is invoked
        # when main process exits
        # It would cause failure when pin_memory_thread tries to read
        # corrupted data from worker_result_queue
        # atexit is used to shutdown thread and child processes in the
        # right sequence before main process exits
        if self.persistent_workers and self.pin_memory:
            import atexit
            for w in self._workers:
                atexit.register(self._clean_up_worker, w)

        # .pid can be None only before process is spawned (not the case, so ignore)
        _utils.signal_handling._set_worker_pids(id(self), tuple(w.pid for w in self._workers))  # type: ignore[misc]
        _utils.signal_handling._set_SIGCHLD_handler()
        self._worker_pids_set = True
        self._reset(first_iter=True)
        
        self._profile_name = "enumerate(DataLoader)#{}.__next__".format(self.__class__.__name__)
        torch.set_vital('DataLoader', 'enabled', 'True')
    
    def _init_index_sampler(self):
        if self.sampler is None:
            if self.shuffle:
                self.sampler = RandomSampler(self.dataset)
            else:
                self.sampler = SequentialSampler(self.dataset)
        if self.batch_size > 0 and self.batch_sampler is None:
            self.batch_sampler = BatchSampler(self.sampler, self.batch_size, self.drop_last)
    
    @property
    def auto_collation(self):
        return self.batch_sampler is not None

    @property
    def _index_sampler(self):
        # The actual sampler used for generating indices for `_DatasetFetcher`
        # (see _utils/fetch.py) to read data at each time. This would be
        # `.batch_sampler` if in auto-collation mode, and `.sampler` otherwise.
        # We can't change `.sampler` and `.batch_sampler` attributes for BC
        # reasons.
        if self.auto_collation:
            return self.batch_sampler
        else:
            return self.sampler
        
    def async_mongo_operator(self):
        try:
            while True:
                collection, func, opertion = self._mongo_operation_queue.get(block=True)
                if func == 'update_many':
                    self.dataset.db[collection].update_many(**opertion)
                # del collection, func, opertion
        except KeyboardInterrupt:
            pass

    def _spawn_worker(self, worker_id=None):
        if self._worker_queue_idx_cycle.reactive_worker() == 1:
            self._active_workers += 1
            return
        
        dataset = _MapDataPipeSerializationWrapper(self.dataset)
        idx_queue = self.multiprocessing_context.Queue()
        idx_queue.cancel_join_thread()
        w = self.multiprocessing_context.Process(target=worker._main_loop, 
                                                 args=(self._dataset_kind, dataset, idx_queue, self._worker_result_queue, self._workers_down_event,
                                                          self.auto_collation, self.collate_fn, self.drop_last, self._base_seed, self.worker_init_fn,
                                                          worker_id, self.num_workers, self.persistent_workers))
        w.daemon = True
        w.start()
        self._index_queues.append(idx_queue)
        self._workers.append(w)
        self._worker_queue_idx_cycle.append(worker_id)
        self._active_workers += 1
    
    def _pause_worker(self):
        if self._worker_queue_idx_cycle.deactive_worker() == 1:
            self._active_workers -= 1
    
    def _reset(self, first_iter=False):    
        self._sampler_iter = iter(self._index_sampler)
        
        # information about data not yet yielded, i.e., tasks w/ indices in range [rcvd_idx, send_idx).
        # map: task idx => - (worker_id,)        if data isn't fetched (outstanding)
        #                  \ (worker_id, data)   if data is already fetched (out-of-order)
        self._reorder_dict = {}
        self._tasks_outstanding = 0  # always equal to count(v for v in _reorder_dict.values() if len(v) == 1)
        
        self._last_iter_time = None
        
        self._req_time = []
        self._load_time = []
        
        self._send_idx = 0  # idx of the next task to be sent to workers
        self._rcvd_idx = 0  # idx of the next task to be returned in __next__
        # information about data not yet yielded, i.e., tasks w/ indices in range [rcvd_idx, send_idx).
        # map: task idx => - (worker_id,)        if data isn't fetched (outstanding)
        #                  \ (worker_id, data)   if data is already fetched (out-of-order)

        # Reset the worker queue cycle so it resumes next epoch at worker 0
        self._worker_queue_idx_cycle.reset()
        
        # We resume the prefetching in case it was enabled
        if not first_iter:
            for idx in range(self._active_workers):
                self._index_queues[idx].put(_utils.worker._ResumeIteration(self._shared_seed))
            resume_iteration_cnt = self._active_workers
            while resume_iteration_cnt > 0:
                return_idx, return_data = self._get_data()
                if isinstance(return_idx, _utils.worker._ResumeIteration):
                    assert return_data is None
                    resume_iteration_cnt -= 1
                    
        # prime the prefetch loop
        for _ in range(self.prefetch_factor * self.num_workers):
            self._try_put_index()
            
    def _tune_worker_num(self):
        # calculate the # of index should be put
        if self._rcvd_idx % self.tune_num_workers_frequency == 0 and len(self._req_time) > 0 and len(self._load_time) > 0:
            # print('active workers: {}'.format(self._active_workers))
            req_interval = statistics.median(self._req_time)
            load_interval = statistics.median(self._load_time)
            # print('req: {}, load: {}'.format(req_interval, load_interval))
            k = math.ceil(load_interval/req_interval) - self._active_workers
            # print('add {} workers'.format(k))
            if k > 0:
                for _ in range(k):
                    if self._active_workers > self.max_num_workers:
                        break
                    self._spawn_worker()
            elif k < 0:
                for _ in range(-k):
                    self._pause_worker()
            self._req_time.clear()
            self._load_time.clear()
    
    def _next_index(self):
        return next(self._sampler_iter)
    
    def _try_put_index(self):
        self._tune_worker_num()
        
        try:
            batched_idxs = self._next_index()
        except StopIteration:
            return

        worker_queue_idx = next(self._worker_queue_idx_cycle)
        self._index_queues[worker_queue_idx].put((self._send_idx, batched_idxs, time.time()))
        self._reorder_dict[self._send_idx] = (worker_queue_idx,)
        self._tasks_outstanding += 1
        self._send_idx += 1
    
    def __iter__(self):
        return self
    
    def __len__(self):
        return len(self._index_sampler)
    
    def _process_next_batch(self, data):
        self._rcvd_idx += 1
        if isinstance(data, worker.ExceptionWrapper):
            data.reraise()
        self._try_put_index()
        return data
    
    def _try_get_data(self, timeout=_utils.MP_STATUS_CHECK_INTERVAL):
        # Tries to fetch data from `self._data_queue` once for a given timeout.
        # This can also be used as inner loop of fetching without timeout, with
        # the sender status as the loop condition.
        #
        # This raises a `RuntimeError` if any worker died expectedly. This error
        # can come from either the SIGCHLD handler in `_utils/signal_handling.py`
        # (only for non-Windows platforms), or the manual check below on errors
        # and timeouts.
        #
        # Returns a 2-tuple:
        #   (bool: whether successfully get data, any: data if successful else None)
        try:
            data = self._data_queue.get(timeout=timeout)
            return (True, data)
        except Exception as e:
            # At timeout and error, we manually check whether any worker has
            # failed. Note that this is the only mechanism for Windows to detect
            # worker failures.
            failed_workers = []
            for worker_id, w in enumerate(self._workers):
                if self._worker_queue_idx_cycle.get_status(worker_id) and not w.is_alive():
                    failed_workers.append(w)
                    self._mark_worker_as_unavailable(worker_id)
            if len(failed_workers) > 0:
                pids_str = ', '.join(str(w.pid) for w in failed_workers)
                raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
            if isinstance(e, queue.Empty):
                return (False, None)
            import tempfile
            import errno
            try:
                # Raise an exception if we are this close to the FDs limit.
                # Apparently, trying to open only one file is not a sufficient
                # test.
                # See NOTE [ DataLoader on Linux and open files limit ]
                fds_limit_margin = 10
                fs = [tempfile.NamedTemporaryFile() for i in range(fds_limit_margin)]
            except OSError as e:
                if e.errno == errno.EMFILE:
                    raise RuntimeError(
                        "Too many open files. Communication with the"
                        " workers is no longer possible. Please increase the"
                        " limit using `ulimit -n` in the shell or change the"
                        " sharing strategy by calling"
                        " `torch.multiprocessing.set_sharing_strategy('file_system')`"
                        " at the beginning of your code") from None
            raise
        
    def _get_data(self):
        if self.timeout > 0:
            success, data = self._try_get_data(self._timeout)
            if success:
                return data
            else:
                raise RuntimeError('DataLoader timed out after {} seconds'.format(self.timeout))
        elif self.pin_memory:
            while self._pin_memory_thread.is_alive():
                success, data = self._try_get_data()
                if success:
                    return data
            else:
                # while condition is false, i.e., pin_memory_thread died.
                raise RuntimeError('Pin memory thread exited unexpectedly')
            # In this case, `self._data_queue` is a `queue.Queue`,. But we don't
            # need to call `.task_done()` because we don't use `.join()`.
        else:
            while True:
                success, data = self._try_get_data()
                if success:
                    return data
                
    def _next_data(self):
        # if self._rcvd_idx == 0:                
            # update chunk status to ACTIVE
            # now = datetime.utcnow().timestamp()
            # self._mongo_operation_queue.put(('Datasets', 'update_many', 
            #                                 {
            #                                     "filter": {"ChunkETag": {"$in": self.dataset.chunk_etags}}, 
            #                                     "update": {
            #                                         "$set": { "Status.code": CHUNK_STATUS.ACTIVE},
            #                                         "$inc": {"Status.active_count": 1},
            #                                         "$push": {"References": bson.timestamp.Timestamp(int(now), inc=1)}}
            #                                 }))
            
            # if self._cool_down_proc is not None and self._cool_down_proc.is_alive():
            #     self._cool_down_proc.terminate()
            #     del self._cool_down_proc
        
        while True:
            while self._rcvd_idx < self._send_idx:
                info = self._reorder_dict[self._rcvd_idx]
                worker_id = info[0]
                if len(info) == 2 or self._worker_queue_idx_cycle.get_status(worker_id):  # has data or is still active
                    break
                del self._reorder_dict[self._rcvd_idx]
                print('del task info {}, len {}'.format(self._rcvd_idx, len(info)))
                self._rcvd_idx += 1
            else:
                if not self.persistent_workers:
                    self._shutdown_workers()
                raise StopIteration

            # Now `self._rcvd_idx` is the batch index we want to fetch
            # Check if the next sample has already been generated
            if len(self._reorder_dict[self._rcvd_idx]) == 2:
                data = self._reorder_dict.pop(self._rcvd_idx)[1]
                return self._process_next_batch(data)
            
            assert not self._shutdown and self._tasks_outstanding > 0
            idx, data, dur  = self._get_data()
            self._tasks_outstanding -= 1
            self._load_time.append(dur)

            if idx != self._rcvd_idx:
                # store out-of-order samples
                self._reorder_dict[idx] += (data,)
            else:
                del self._reorder_dict[idx]
                return self._process_next_batch(data)
                
            
    def __next__(self):
        with torch.autograd.profiler.record_function(self._profile_name):
            try:
                if self._sampler_iter is None:
                    print('self._sampler_iter is None')
                    self._reset()
                
                if self._last_iter_time is not None:
                    self._req_time.append(time.time()-self._last_iter_time)

                self._last_iter_time = time.time()
                data = self._next_data()
                return data
            except StopIteration:
                print('raise StopIteration Exception....')

                # epoch is down
                # if self._partition_idx == len(self.dataset._sample_chunks)-1:
                if self._partition_idx == 0:
                    self._partition_idx = 0
                    
                    # update chunk status to COOL_DOWN
                    now = datetime.utcnow().timestamp()
                    # self._mongo_operation_queue.put(("Datasets", "update_many", 
                    #                                 {
                    #                                     "filter": {
                    #                                         "ChunkETag": {"$in": self.dataset.chunk_etags},
                    #                                         "Status.active_count": 1
                    #                                     },
                    #                                     "update": {"$set": {
                    #                                         "Status.code": CHUNK_STATUS.INACTIVE,
                    #                                         "Status.active_count": 0,
                    #                                         "Status.cool_down_init": bson.timestamp.Timestamp(int(now), inc=1)}
                    #                                     }
                    #                                 }))
                    # self._mongo_operation_queue.put(("Datasets", "update_many", 
                    #                                 {
                    #                                     "filter": {
                    #                                         "ChunkETag": {"$in": self.dataset.chunk_etags},
                    #                                         "Status.active_count": {"$gt": 1}
                    #                                     },
                    #                                     "update": {
                    #                                         "$inc": {"Status.active_count": -1},
                    #                                         "$set": {
                    #                                             "Status.code": CHUNK_STATUS.INACTIVE,
                    #                                             "Status.cool_down_init": bson.timestamp.Timestamp(int(now), inc=1)
                    #                                         }
                    #                                     }
                    #                                 }))
                    
                    # self._cool_down_proc = multiprocessing.Process(target=self.expire_chunks, daemon=True)
                    # self._cool_down_proc.start()
                    raise StopIteration
                else:                    
                    # data in the current part have been consumed    
                    self._partition_idx += 1
                    # notify workers to move _partition_idx
                    for i in range(len(self._index_queues)):
                        self._index_queues[i].put((None, self._partition_idx))
                    
                    # refresh iterator
                    self.dataset.load_data(self._partition_idx)
                    self._init_index_sampler()
                    self._reset()
                     
                    data = self._next_data()
                    self._last_iter_time = time.time()
                    return data
    
    # def expire_chunks(self):
    #     time.sleep(COOL_DOWN_SEC)   
    #     self._mongo_operation_queue.put(("Datasets", "update_many", 
    #                                      {
    #                                          "filter": {
    #                                              "ChunkETag": {"$in": self.dataset.chunk_etags},
    #                                              "Status.code": CHUNK_STATUS.COOL_DOWN
    #                                          },
    #                                          "update": {
    #                                              "$set":{
    #                                                  "Status.code": CHUNK_STATUS.INACTIVE,
    #                                                  "Status.active_count": 0
    #                                              }
    #                                          }
    #                                      }))
        
    def _mark_worker_as_unavailable(self, worker_id, shutdown=False):
        # Mark a worker as having finished its work e.g., due to
        # exhausting an `IterableDataset`. This should be used only when this
        # `_MultiProcessingDataLoaderIter` is going to continue running.

        assert self._worker_queue_idx_cycle.get_status(worker_id) or (self.persistent_workers and shutdown)

        # Signal termination to that specific worker.
        q = self._index_queues[worker_id]
        # Indicate that no more data will be put on this queue by the current
        # process.
        q.put(None)

        # Note that we don't actually join the worker here, nor do we remove the
        # worker's pid from C side struct because (1) joining may be slow, and
        # (2) since we don't join, the worker may still raise error, and we
        # prefer capturing those, rather than ignoring them, even though they
        # are raised after the worker has finished its job.
        # Joinning is deferred to `_shutdown_workers`, which it is called when
        # all workers finish their jobs (e.g., `IterableDataset` replicas) or
        # when this iterator is garbage collected.

        self._worker_queue_idx_cycle.set_status(worker_id, False)

        assert self._workers_down_event.is_set() == shutdown

    def _shutdown_workers(self):
        # Called when shutting down this `_MultiProcessingDataLoaderIter`.
        # See NOTE [ Data Loader Multiprocessing Shutdown Logic ] for details on
        # the logic of this function.
        if _utils is None or _utils.python_exit_status is True or _utils.python_exit_status is None:
            # See (2) of the note. If Python is shutting down, do no-op.
            return
        # Normal exit when last reference is gone / iterator is depleted.
        # See (1) and the second half of the note.
        if not self._shutdown:
            self._shutdown = True
            try:
                # Normal exit when last reference is gone / iterator is depleted.
                # See (1) and the second half of the note.

                # Exit `pin_memory_thread` first because exiting workers may leave
                # corrupted data in `worker_result_queue` which `pin_memory_thread`
                # reads from.
                if hasattr(self, '_pin_memory_thread'):
                    # Use hasattr in case error happens before we set the attribute.
                    self._pin_memory_thread_done_event.set()
                    # Send something to pin_memory_thread in case it is waiting
                    # so that it can wake up and check `pin_memory_thread_done_event`
                    self._worker_result_queue.put((None, None))
                    self._pin_memory_thread.join()
                    self._worker_result_queue.cancel_join_thread()
                    self._worker_result_queue.close()

                # Exit workers now.
                self._workers_down_event.set()
                for worker_id in range(len(self._workers)):
                    # Get number of workers from `len(self._workers)` instead of
                    # `self._num_workers` in case we error before starting all
                    # workers.
                    # If we are using workers_status with persistent_workers
                    # we have to shut it down because the worker is paused
                    if self.persistent_workers or self._worker_queue_idx_cycle.get_status(worker_id):
                        self._mark_worker_as_unavailable(worker_id, shutdown=True)
                for w in self._workers:
                    # We should be able to join here, but in case anything went
                    # wrong, we set a timeout and if the workers fail to join,
                    # they are killed in the `finally` block.
                    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
                for q in self._index_queues:
                    q.cancel_join_thread()
                    q.close()
            finally:
                # Even though all this function does is putting into queues that
                # we have called `cancel_join_thread` on, weird things can
                # happen when a worker is killed by a signal, e.g., hanging in
                # `Event.set()`. So we need to guard this with SIGCHLD handler,
                # and remove pids from the C side data structure only at the
                # end.
                #
                # FIXME: Unfortunately, for Windows, we are missing a worker
                #        error detection mechanism here in this function, as it
                #        doesn't provide a SIGCHLD handler.
                if self._worker_pids_set:
                    _utils.signal_handling._remove_worker_pids(id(self))
                    self._worker_pids_set = False
                for w in self._workers:
                    if w.is_alive():
                        # Existing mechanisms try to make the workers exit
                        # peacefully, but in case that we unfortunately reach
                        # here, which we shouldn't, (e.g., pytorch/pytorch#39570),
                        # we kill the worker.
                        w.terminate()

    # staticmethod is used to remove reference to `_MultiProcessingDataLoaderIter`
    @staticmethod
    def _clean_up_worker(w):
        try:
            w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
        finally:
            if w.is_alive():
                w.terminate()

    def __del__(self):
        self._shutdown_workers()
